#!/usr/bin/env python3
"""Evaluate NMF auto-detection across synthetic grammars of varying size.

Generates random PCFGs using syntheticpcfg.FullPCFGFactory (with all
binary rules, LogNormal lexical distribution, trained length model),
samples corpora, runs the NMF kernel auto-detection, and evaluates
whether the correct number of nonterminals is found and whether the
kernels are good anchors.

Results are saved to a JSON file and plotted.

Usage:
    python3 evaluate_autodetect.py results.json --plot results.png
    python3 evaluate_autodetect.py results.json --quick   # fast subset
"""

import sys
import os
import json
import argparse
import tempfile
import time
import logging

import numpy as np
import numpy.random

# Add packages to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__)))
SYNTHETICPCFG_PATH = os.path.join(os.path.dirname(__file__),
    '..', '..', '..', 'cursor_syntheticpcfg', 'syntheticpcfg')
sys.path.insert(0, SYNTHETICPCFG_PATH)

import wcfg
import locallearner as ll_module
import evaluation

from syntheticpcfg import pcfgfactory, pcfg as spcfg, utility as sutil


def compute_grammar_difficulty(grammar):
    """Compute difficulty metrics from the PCFG structure.

    Computes two types of condition numbers:

    1. Lexical emission matrix (N×T): P(terminal | NT).
       Always well-conditioned when T >> N (uninformative).

    2. Nonterminal context matrix (N×2N): the distribution over
       adjacent nonterminals for each NT, computed analytically from
       the grammar's binary rules. This captures what the NMF
       actually decomposes (context distributions), and its condition
       number predicts whether NTs are distinguishable from context.

    Also computes:
    - Min pairwise KL divergence between lexical distributions
    - Min pairwise KL between context distributions

    Returns dict with all metrics.
    """
    nts = sorted(grammar.nonterminals)
    terms = sorted(grammar.terminals)
    nt_idx = {nt: i for i, nt in enumerate(nts)}
    t_idx = {t: j for j, t in enumerate(terms)}
    N = len(nts)
    T = len(terms)

    # ---- 1. Lexical emission matrix ----
    E = np.zeros((N, T))
    for prod, p in grammar.parameters.items():
        if len(prod) == 2:
            nt, terminal = prod
            if nt in nt_idx and terminal in t_idx:
                E[nt_idx[nt], t_idx[terminal]] = p

    row_sums = E.sum(axis=1, keepdims=True)
    row_sums = np.maximum(row_sums, 1e-300)
    E_norm = E / row_sums

    lex_svd = np.linalg.svd(E_norm, compute_uv=False)
    lex_cond = float(lex_svd[0] / lex_svd[N - 1]) if lex_svd[N - 1] > 0 else float('inf')

    # Min pairwise KL between lexical distributions
    min_lex_kl = float('inf')
    for i in range(N):
        for j in range(i + 1, N):
            kl_ij = _kl_divergence(E_norm[i], E_norm[j])
            kl_ji = _kl_divergence(E_norm[j], E_norm[i])
            sym_kl = (kl_ij + kl_ji) / 2
            if sym_kl < min_lex_kl:
                min_lex_kl = sym_kl

    # ---- 2. Nonterminal context matrix (analytical) ----
    # lex_prob[A] = P(A generates a terminal directly)
    lex_prob = np.zeros(N)
    for prod, p in grammar.parameters.items():
        if len(prod) == 2:
            lex_prob[nt_idx[prod[0]]] += p

    # M_right[A, D] = Σ_C P(A -> C D): contribution of D to rightmost leaf of A
    M_right = np.zeros((N, N))
    # M_left[A, C] = Σ_D P(A -> C D): contribution of C to leftmost leaf of A
    M_left = np.zeros((N, N))
    for prod, p in grammar.parameters.items():
        if len(prod) == 3:
            a, b, c = prod
            if a in nt_idx and b in nt_idx and c in nt_idx:
                M_right[nt_idx[a], nt_idx[c]] += p
                M_left[nt_idx[a], nt_idx[b]] += p

    # rnt[A, B] = P(rightmost leaf of A's subtree is generated by NT B)
    # rnt = (I - M_right)^{-1} * diag(lex_prob)
    try:
        rnt = np.linalg.solve(np.eye(N) - M_right, np.diag(lex_prob))
    except np.linalg.LinAlgError:
        rnt = np.eye(N) * (1.0 / N)

    # lnt[A, B] = P(leftmost leaf of A's subtree is generated by NT B)
    try:
        lnt = np.linalg.solve(np.eye(N) - M_left, np.diag(lex_prob))
    except np.linalg.LinAlgError:
        lnt = np.eye(N) * (1.0 / N)

    # Nonterminal expectations E[A]
    # E = (I - (M_left + M_right)^T)^{-1} * e_S
    M_total = M_left + M_right
    e_start = np.zeros(N)
    start_nt = grammar.start
    if start_nt in nt_idx:
        e_start[nt_idx[start_nt]] = 1.0
    try:
        nt_expect = np.linalg.solve(np.eye(N) - M_total.T, e_start)
    except np.linalg.LinAlgError:
        nt_expect = np.ones(N)
    nt_expect = np.maximum(nt_expect, 0)

    # Bigram NT matrix: B[A, B] = expected count of (word from A, word from B adjacent)
    # B[A, B] = Σ_{P,C,D} P(P->CD) * E[P] * rnt[C,A] * lnt[D,B]
    bigram = np.zeros((N, N))
    for prod, p in grammar.parameters.items():
        if len(prod) == 3:
            parent, left_child, right_child = prod
            if parent in nt_idx and left_child in nt_idx and right_child in nt_idx:
                pi = nt_idx[parent]
                li = nt_idx[left_child]
                ri = nt_idx[right_child]
                weight = p * nt_expect[pi]
                # rnt[li, :] gives rightmost-NT distribution for left child
                # lnt[ri, :] gives leftmost-NT distribution for right child
                bigram += weight * np.outer(rnt[li, :], lnt[ri, :])

    # Context feature matrix: for each NT A, concatenate its left and right
    # context NT distributions.
    # Right context of A: row A of bigram (normalized)
    # Left context of A: column A of bigram (normalized)
    ctx_right = bigram.copy()
    ctx_left = bigram.T.copy()

    # Normalize rows
    for i in range(N):
        s = ctx_right[i].sum()
        if s > 0:
            ctx_right[i] /= s
        s = ctx_left[i].sum()
        if s > 0:
            ctx_left[i] /= s

    # N × 2N context matrix
    ctx_matrix = np.hstack([ctx_left, ctx_right])

    ctx_svd = np.linalg.svd(ctx_matrix, compute_uv=False)
    n_sv = min(N, 2 * N)
    ctx_sigma_min = ctx_svd[N - 1] if N <= 2 * N else ctx_svd[2 * N - 1]
    if ctx_sigma_min > 0:
        ctx_cond = float(ctx_svd[0] / ctx_sigma_min)
    else:
        ctx_cond = float('inf')

    ctx_log_cond = np.log10(ctx_cond) if ctx_cond < float('inf') else float('inf')

    # Numerical rank of context matrix
    threshold = 1e-10 * ctx_svd[0] if ctx_svd[0] > 0 else 1e-10
    ctx_rank = int(np.sum(ctx_svd > threshold))

    # Min pairwise symmetric KL between context distributions
    min_ctx_kl = float('inf')
    for i in range(N):
        for j in range(i + 1, N):
            kl_ij = _kl_divergence(ctx_matrix[i], ctx_matrix[j])
            kl_ji = _kl_divergence(ctx_matrix[j], ctx_matrix[i])
            sym_kl = (kl_ij + kl_ji) / 2
            if sym_kl < min_ctx_kl:
                min_ctx_kl = sym_kl

    # ---- Terminal-level context matrix (N × 2T) ----
    # Project the NT-level context distributions through the lexical
    # emission matrix to get terminal-level context distributions.
    # This captures what the NMF actually sees (modulo clustering).
    ctx_term_left = ctx_left @ E_norm     # N × T
    ctx_term_right = ctx_right @ E_norm   # N × T
    ctx_term = np.hstack([ctx_term_left, ctx_term_right])  # N × 2T

    # SVD of terminal-level context matrix
    ctx_term_svd = np.linalg.svd(ctx_term, compute_uv=False)

    # Effective condition number: σ_1 / σ_{N-1}
    # (The N-th singular value is ~0 due to structural rank deficiency
    #  from the start symbol constraint, so we use σ_{N-1} instead.)
    if N >= 2 and len(ctx_term_svd) >= N - 1:
        sigma_1 = ctx_term_svd[0]
        sigma_n1 = ctx_term_svd[N - 2]  # (N-1)-th singular value, 0-indexed
        sigma_n = ctx_term_svd[N - 1] if len(ctx_term_svd) >= N else 0.0
        if sigma_n1 > 1e-15:
            eff_ctx_cond = float(sigma_1 / sigma_n1)
        else:
            eff_ctx_cond = float('inf')
    else:
        eff_ctx_cond = float('inf')
        sigma_1 = 0.0
        sigma_n1 = 0.0
        sigma_n = 0.0

    eff_ctx_log_cond = np.log10(eff_ctx_cond) if np.isfinite(eff_ctx_cond) else float('inf')

    # ---- 3. Anchor quality metrics ----
    # For each NT A, find the best anchor: max_t P(A | t)
    # P(A | t) = P(A->t) * E[A] / Σ_B P(B->t) * E[B]
    #
    # This directly measures whether each NT has a word that is
    # predominantly generated by it — exactly what the NMF needs.

    # Terminal expectations: E[t] = Σ_A P(A->t) * E[A]
    term_expect = np.zeros(T)
    prod_expect = np.zeros((N, T))  # P(A->t) * E[A]
    for prod, p in grammar.parameters.items():
        if len(prod) == 2:
            nt, terminal = prod
            if nt in nt_idx and terminal in t_idx:
                i, j = nt_idx[nt], t_idx[terminal]
                pe = p * nt_expect[i]
                prod_expect[i, j] = pe
                term_expect[j] += pe

    # Posterior matrix: P(A | t)
    posterior = np.zeros((N, T))
    for j in range(T):
        if term_expect[j] > 0:
            posterior[:, j] = prod_expect[:, j] / term_expect[j]

    # Best anchor quality per NT
    best_anchor = np.max(posterior, axis=1)  # max over terminals for each NT
    min_best_anchor = float(np.min(best_anchor))
    mean_best_anchor = float(np.mean(best_anchor))

    # Also compute condition number of posterior matrix (N×T)
    # Only consider terminals with non-zero expectation
    active_cols = term_expect > 0
    if np.sum(active_cols) >= N:
        post_active = posterior[:, active_cols]
        post_svd = np.linalg.svd(post_active, compute_uv=False)
        post_sigma_min = post_svd[N - 1] if len(post_svd) >= N else 0.0
        if post_sigma_min > 0:
            post_cond = float(post_svd[0] / post_sigma_min)
        else:
            post_cond = float('inf')
    else:
        post_cond = float('inf')
        post_svd = np.array([0.0])

    post_log_cond = np.log10(post_cond) if post_cond < float('inf') else float('inf')

    return {
        'lex_condition_number': float(lex_cond),
        'lex_log_condition_number': float(np.log10(lex_cond)) if lex_cond < float('inf') else float('inf'),
        'min_lex_kl': float(min_lex_kl),
        'ctx_condition_number': float(ctx_cond),
        'ctx_log_condition_number': float(ctx_log_cond),
        'ctx_singular_values': [float(s) for s in ctx_svd[:N]],
        'ctx_min_singular_value': float(ctx_sigma_min),
        'ctx_rank': ctx_rank,
        'ctx_full_rank': ctx_rank >= N,
        'min_ctx_kl': float(min_ctx_kl),
        'min_best_anchor': min_best_anchor,
        'mean_best_anchor': mean_best_anchor,
        'best_anchor_per_nt': [float(x) for x in best_anchor],
        'post_condition_number': float(post_cond),
        'post_log_condition_number': float(post_log_cond),
        'eff_ctx_condition_number': float(eff_ctx_cond),
        'eff_ctx_log_condition_number': float(eff_ctx_log_cond),
        'condition_number': float(eff_ctx_cond),          # primary metric
        'log_condition_number': float(eff_ctx_log_cond),  # primary metric (log)
        'rank': ctx_rank,
        'full_rank': ctx_rank >= N,
        'min_singular_value': float(ctx_sigma_min),
    }


def _kl_divergence(p, q):
    """KL(p || q) with zero-handling."""
    d = 0.0
    for pi, qi in zip(p, q):
        if pi > 1e-15:
            if qi <= 1e-15:
                return float('inf')
            d += pi * np.log(pi / qi)
    return d


def generate_grammar(n_nonterminals, n_terminals, seed):
    """Generate a random PCFG using FullPCFGFactory.

    Uses the same settings as the existing data/ grammars:
    - LogNormal(sigma=4.0) lexical distribution (skewed → good anchors)
    - Dirichlet(alpha = 1/((n-1)^2+1)) binary distribution
    - Poisson(5.0) length distribution
    - Full CNF backbone (all binary rules present)
    """
    numpy.random.seed(seed)

    factory = pcfgfactory.FullPCFGFactory(
        nonterminals=n_nonterminals,
        terminals=n_terminals
    )
    factory.lexical_distribution = pcfgfactory.LogNormalPrior(sigma=4.0)
    alpha = 1.0 / ((n_nonterminals - 1) ** 2 + 1)
    factory.binary_distribution = pcfgfactory.LexicalDirichlet(dirichlet=alpha)
    factory.length_distribution = pcfgfactory.LengthDistribution()
    factory.length_distribution.set_poisson(5.0, 20)

    grammar = factory.sample_uniform()
    return grammar


def sample_corpus(grammar, n_sentences, seed):
    """Sample a corpus from a PCFG, return list of yield strings."""
    rng = numpy.random.RandomState(seed)
    sampler = spcfg.Sampler(grammar, random=rng)
    sentences = []
    for _ in range(n_sentences):
        tree = sampler.sample_tree()
        s = sutil.collect_yield(tree)
        sentences.append(' '.join(s))
    return sentences


def run_autodetect(corpus_path, seed=42, min_count=10, number_clusters=10):
    """Run NMF auto-detection and return kernels, learner, elapsed time."""
    learner = ll_module.LocalLearner(corpus_path)
    learner.nonterminals = 0  # auto-detect
    learner.number_clusters = number_clusters
    learner.min_count_nmf = min_count
    learner.seed = seed
    learner.max_nonterminals = 30

    t0 = time.time()
    kernels = learner.find_kernels(verbose=False)
    elapsed = time.time() - t0

    return kernels, learner, elapsed


def run_fixed_count(corpus_path, n_nonterminals, seed=42, min_count=10,
                    number_clusters=10):
    """Run NMF with a fixed number of nonterminals (no auto-detection).

    Returns the first n_nonterminals kernels selected by the NMF,
    bypassing all stopping criteria.
    """
    learner = ll_module.LocalLearner(corpus_path)
    learner.nonterminals = n_nonterminals
    learner.number_clusters = number_clusters
    learner.min_count_nmf = min_count
    learner.seed = seed

    kernels = learner.find_kernels(verbose=False)
    return kernels, learner


def evaluate_kernels_against_target(target_path, kernels):
    """Evaluate kernel quality against the target grammar.

    Returns a dict with evaluation metrics, or None-filled if
    kernel count doesn't match target NT count.
    """
    target = wcfg.load_wcfg_from_file(target_path)
    n_target = len(target.nonterminals)

    if len(kernels) == n_target:
        result = evaluation.evaluate_kernels_hungarian(target, kernels)
        return {
            'mean_posterior': result['mean_posterior'],
            'min_posterior': result['min_posterior'],
            'accuracy': result['accuracy'],
        }
    else:
        return {
            'mean_posterior': None,
            'min_posterior': None,
            'accuracy': None,
        }


def run_experiment(config):
    """Run a single experiment configuration. Returns a result dict."""
    n_nt = config['n_nonterminals']
    n_t = config['n_terminals']
    n_sentences = config['n_sentences']
    n_clusters = config.get('n_clusters', 10)
    grammar_seed = config['grammar_seed']
    corpus_seed = config['corpus_seed']

    result = {
        'n_nonterminals': n_nt,
        'n_terminals': n_t,
        'n_sentences': n_sentences,
        'n_clusters': n_clusters,
        'grammar_seed': grammar_seed,
        'corpus_seed': corpus_seed,
    }

    try:
        # Generate grammar
        grammar = generate_grammar(n_nt, n_t, grammar_seed)

        # Compute grammar difficulty metrics (from the PCFG, not the data)
        difficulty = compute_grammar_difficulty(grammar)
        result.update({
            'condition_number': difficulty['condition_number'],
            'log_condition_number': difficulty['log_condition_number'],
            'min_singular_value': difficulty['min_singular_value'],
            'rank': difficulty['rank'],
            'full_rank': difficulty['full_rank'],
            'lex_log_condition_number': difficulty['lex_log_condition_number'],
            'ctx_log_condition_number': difficulty['ctx_log_condition_number'],
            'min_lex_kl': difficulty['min_lex_kl'],
            'min_ctx_kl': difficulty['min_ctx_kl'],
            'min_best_anchor': difficulty['min_best_anchor'],
            'mean_best_anchor': difficulty['mean_best_anchor'],
            'post_log_condition_number': difficulty['post_log_condition_number'],
            'eff_ctx_log_condition_number': difficulty['eff_ctx_log_condition_number'],
        })

        with tempfile.TemporaryDirectory() as tmpdir:
            # Store grammar
            grammar_path = os.path.join(tmpdir, 'grammar.pcfg')
            grammar.store(grammar_path)

            # Sample corpus
            sentences = sample_corpus(grammar, n_sentences, corpus_seed)
            corpus_path = os.path.join(tmpdir, 'corpus.txt')
            with open(corpus_path, 'w') as f:
                for s in sentences:
                    f.write(s + '\n')

            # Adjust min_count based on corpus size
            min_count = max(5, n_sentences // 1000)

            # Run auto-detection
            kernels, learner, elapsed = run_autodetect(
                corpus_path, seed=42, min_count=min_count,
                number_clusters=n_clusters
            )

            result['n_detected'] = len(kernels)
            result['correct_count'] = len(kernels) == n_nt
            result['delta'] = len(kernels) - n_nt
            result['elapsed'] = round(elapsed, 2)
            result['kernels'] = kernels

            # Capture stopping diagnostics
            result['stop_reason'] = getattr(learner, 'stop_reason', None)
            result['stop_boot_p'] = getattr(learner, 'stop_boot_p', None)
            result['stop_wctx_max_p'] = getattr(learner, 'stop_wctx_max_p', None)
            result['stop_wctx_min_v'] = getattr(learner, 'stop_wctx_min_v', None)

            # Evaluate kernel quality (auto-detected)
            eval_result = evaluate_kernels_against_target(grammar_path, kernels)
            result.update(eval_result)

            # Also run with the true NT count to check if the first N
            # kernels are correct anchors (regardless of stopping criterion)
            fixed_kernels, _ = run_fixed_count(
                corpus_path, n_nt, seed=42, min_count=min_count,
                number_clusters=n_clusters
            )
            fixed_eval = evaluate_kernels_against_target(
                grammar_path, fixed_kernels)
            result['fixed_kernels'] = fixed_kernels
            result['fixed_mean_posterior'] = fixed_eval['mean_posterior']
            result['fixed_min_posterior'] = fixed_eval['min_posterior']
            result['fixed_accuracy'] = fixed_eval['accuracy']

    except Exception as e:
        import traceback
        result['error'] = str(e)
        result['traceback'] = traceback.format_exc()
        result['n_detected'] = None
        result['correct_count'] = False
        result['delta'] = None

    return result


def build_experiment_grid(args):
    """Build the experiment configurations."""
    configs = []

    if args.quick:
        nt_sizes = [3, 5, 10]
        corpus_sizes = [50000]
        cluster_sizes = [10]
        n_terminals = 1000
        n_repeats = 2
    else:
        nt_sizes = [3, 5, 8, 10]
        corpus_sizes = [50000, 100000]
        cluster_sizes = [10]
        n_terminals = 1000
        n_repeats = args.repeats

    for n_nt in nt_sizes:
        for n_s in corpus_sizes:
            for n_cl in cluster_sizes:
                for rep in range(n_repeats):
                    configs.append({
                        'n_nonterminals': n_nt,
                        'n_terminals': n_terminals,
                        'n_sentences': n_s,
                        'n_clusters': n_cl,
                        'grammar_seed': 1000 * rep + n_nt * 7 + 1,
                        'corpus_seed': 2000 * rep + 1,
                    })

    return configs


def run_all_experiments(args):
    """Run the full experiment grid."""
    configs = build_experiment_grid(args)
    total = len(configs)
    results = []

    for i, config in enumerate(configs):
        label = (f"NT={config['n_nonterminals']}, "
                 f"C={config.get('n_clusters', 10)}, "
                 f"N={config['n_sentences']}, "
                 f"seed={config['grammar_seed']}")
        print(f"[{i+1}/{total}] {label} ...", end=' ', flush=True)

        result = run_experiment(config)
        results.append(result)

        if result.get('error'):
            print(f"ERROR: {result['error'][:60]}")
        else:
            ok = 'OK' if result['correct_count'] else 'WRONG'
            det = result['n_detected']
            delta = result['delta']
            elc = result.get('eff_ctx_log_condition_number', 0)
            info = f"detected={det} (delta={delta:+d}, {ok})"
            info += f", effCtxLogC={elc:.2f}"
            if result.get('mean_posterior') is not None:
                info += f", post={result['mean_posterior']:.3f}"
            # Show fixed-count kernel quality
            fmp = result.get('fixed_mean_posterior')
            if fmp is not None:
                info += f", fixed_post={fmp:.3f}"
            print(f"{info}, {result['elapsed']:.1f}s")

    return results


def print_summary(results):
    """Print a summary table of results."""
    from collections import defaultdict

    valid = [r for r in results if not r.get('error')]
    if not valid:
        print("No valid results.")
        return

    # Group by (n_nt, n_clusters)
    groups = defaultdict(list)
    for r in valid:
        key = (r['n_nonterminals'], r.get('n_clusters', 10))
        groups[key].append(r)

    print("\n" + "=" * 95)
    print(f"{'NTs':>4s} {'Clust':>6s} {'Trials':>6s} "
          f"{'Correct':>7s} {'Rate':>6s} {'MeanDelta':>9s} {'MeanPost':>8s}"
          f" {'FixedPost':>9s} {'FixedAcc':>8s}")
    print("-" * 95)

    nt_vals = sorted(set(r['n_nonterminals'] for r in valid))
    cl_vals = sorted(set(r.get('n_clusters', 10) for r in valid))

    for n_nt in nt_vals:
        for n_cl in cl_vals:
            key = (n_nt, n_cl)
            if key not in groups:
                continue
            rs = groups[key]
            n = len(rs)
            correct = sum(1 for r in rs if r['correct_count'])
            rate = correct / n if n > 0 else 0
            mean_delta = np.mean([r['delta'] for r in rs])
            posteriors = [r['mean_posterior'] for r in rs
                          if r['mean_posterior'] is not None]
            mp = np.mean(posteriors) if posteriors else float('nan')

            # Fixed-count kernel quality
            fpost = [r['fixed_mean_posterior'] for r in rs
                     if r.get('fixed_mean_posterior') is not None]
            fmp = np.mean(fpost) if fpost else float('nan')
            facc = [r['fixed_accuracy'] for r in rs
                    if r.get('fixed_accuracy') is not None]
            fa = np.mean(facc) if facc else float('nan')

            print(f"{n_nt:4d} {n_cl:6d} {n:6d} "
                  f"{correct:7d} {rate:6.1%} {mean_delta:+9.1f} {mp:8.3f}"
                  f" {fmp:9.3f} {fa:8.3f}")

    # Summary by cluster count
    print("\n--- Accuracy by cluster count ---")
    by_cluster = defaultdict(list)
    for r in valid:
        by_cluster[r.get('n_clusters', 10)].append(r['correct_count'])
    for n_cl in sorted(by_cluster.keys()):
        vals = by_cluster[n_cl]
        print(f"  Clusters={n_cl:>3d}: {sum(vals)}/{len(vals)} "
              f"({sum(vals)/len(vals):.1%})")

    # Summary by NT count
    print("\n--- Accuracy by nonterminal count ---")
    by_nt = defaultdict(list)
    for r in valid:
        by_nt[r['n_nonterminals']].append(r['correct_count'])
    for n_nt in sorted(by_nt.keys()):
        vals = by_nt[n_nt]
        print(f"  NTs={n_nt:>2d}: {sum(vals)}/{len(vals)} "
              f"({sum(vals)/len(vals):.1%})")

    # Summary by grammar (unique seed), showing condition number
    print("\n--- Per-grammar summary (aggregated over corpus sizes) ---")
    by_grammar = defaultdict(list)
    for r in valid:
        key = (r['n_nonterminals'], r['grammar_seed'])
        by_grammar[key].append(r)
    print(f"{'NTs':>4s} {'Seed':>6s} {'effCtxLC':>9s} {'postLogC':>9s} "
          f"{'lexLogC':>8s} "
          f"{'Trials':>6s} {'Correct':>7s} {'Rate':>6s}")
    print("-" * 70)
    for key in sorted(by_grammar.keys()):
        rs = by_grammar[key]
        n = len(rs)
        correct = sum(1 for r in rs if r['correct_count'])
        rate = correct / n
        elc = rs[0].get('eff_ctx_log_condition_number', float('nan'))
        plc = rs[0].get('post_log_condition_number', float('nan'))
        lex_cond = rs[0].get('lex_log_condition_number', float('nan'))
        print(f"{key[0]:4d} {key[1]:6d} {elc:9.2f} {plc:9.2f} "
              f"{lex_cond:8.2f} "
              f"{n:6d} {correct:7d} {rate:6.1%}")


def plot_results(results, output_path):
    """Plot comprehensive results for the combined bootstrap + word-context
    stopping criterion evaluation."""
    import matplotlib
    matplotlib.use('Agg')
    import matplotlib.pyplot as plt
    from collections import defaultdict

    valid = [r for r in results if not r.get('error') and r.get('delta') is not None]
    if not valid:
        print("No valid results to plot.")
        return

    nt_vals = sorted(set(r['n_nonterminals'] for r in valid))
    corpus_vals = sorted(set(r['n_sentences'] for r in valid))

    # Color scheme
    colors = plt.cm.tab10(np.linspace(0, 0.4, len(nt_vals)))
    nt_color = {nt: colors[i] for i, nt in enumerate(nt_vals)}

    fig, axes = plt.subplots(2, 3, figsize=(18, 11))
    fig.suptitle('NMF Auto-detection: Combined Bootstrap + Word-Context Stopping',
                 fontsize=14, fontweight='bold', y=0.98)

    # --- Plot 1: Accuracy by NT count (grouped bar chart) ---
    ax = axes[0, 0]
    x_pos = np.arange(len(nt_vals))
    bar_w = 0.35
    for j, n_s in enumerate(corpus_vals):
        rates = []
        counts = []
        for n_nt in nt_vals:
            subset = [r for r in valid
                      if r['n_nonterminals'] == n_nt
                      and r['n_sentences'] == n_s]
            n = len(subset)
            c = sum(1 for r in subset if r['correct_count'])
            rates.append(c / n if n > 0 else 0)
            counts.append(f'{c}/{n}')
        offset = (j - (len(corpus_vals) - 1) / 2) * bar_w
        bars = ax.bar(x_pos + offset, rates, bar_w * 0.9,
                      label=f'N={n_s//1000}K', alpha=0.85)
        for k, (bar, ct) in enumerate(zip(bars, counts)):
            ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.02,
                    ct, ha='center', va='bottom', fontsize=8)
    ax.set_xticks(x_pos)
    ax.set_xticklabels([f'{nt} NTs' for nt in nt_vals])
    ax.set_ylabel('Accuracy (exact NT count)')
    ax.set_title('Detection accuracy by grammar size')
    ax.set_ylim(0, 1.15)
    ax.legend()
    ax.grid(True, alpha=0.2, axis='y')

    # --- Plot 2: Delta distribution (box plot) ---
    ax = axes[0, 1]
    box_data = []
    box_labels = []
    box_positions = []
    pos = 0
    for n_nt in nt_vals:
        for j, n_s in enumerate(corpus_vals):
            subset = [r for r in valid
                      if r['n_nonterminals'] == n_nt
                      and r['n_sentences'] == n_s]
            deltas = [r['delta'] for r in subset]
            if deltas:
                box_data.append(deltas)
                box_labels.append(f'{n_nt}\n{n_s//1000}K')
                box_positions.append(pos)
            pos += 1
        pos += 0.5  # gap between NT groups
    bp = ax.boxplot(box_data, positions=box_positions, widths=0.6,
                    patch_artist=True, showmeans=True,
                    meanprops=dict(marker='D', markerfacecolor='red',
                                   markersize=5))
    # Color boxes by NT count
    idx = 0
    for n_nt in nt_vals:
        for _ in corpus_vals:
            if idx < len(bp['boxes']):
                bp['boxes'][idx].set_facecolor(nt_color[n_nt])
                bp['boxes'][idx].set_alpha(0.6)
            idx += 1
    ax.set_xticks(box_positions)
    ax.set_xticklabels(box_labels, fontsize=7)
    ax.axhline(y=0, color='black', linestyle='--', linewidth=1, alpha=0.7)
    ax.set_ylabel('Delta (detected - true)')
    ax.set_title('Detection bias distribution')
    ax.grid(True, alpha=0.2, axis='y')

    # --- Plot 3: Detected vs True scatter ---
    ax = axes[0, 2]
    for n_s in corpus_vals:
        subset = [r for r in valid if r['n_sentences'] == n_s]
        true_nts = [r['n_nonterminals'] for r in subset]
        det_nts = [r['n_detected'] for r in subset]
        # Add jitter for visibility
        jitter = np.random.RandomState(42).uniform(-0.2, 0.2, len(true_nts))
        ax.scatter(np.array(true_nts) + jitter, det_nts,
                   alpha=0.5, s=30, label=f'N={n_s//1000}K')
    max_nt = max(nt_vals)
    ax.plot([0, max_nt + 2], [0, max_nt + 2], 'k--', alpha=0.5,
            label='perfect')
    ax.set_xlabel('True number of NTs')
    ax.set_ylabel('Detected NTs')
    ax.set_title('Detected vs True NT count')
    ax.legend(fontsize=8)
    ax.set_xlim(min(nt_vals) - 1, max_nt + 2)
    ax.grid(True, alpha=0.2)

    # --- Plot 4: Stopping reason breakdown ---
    ax = axes[1, 0]
    stop_reasons = ['bootstrap', 'word_ctx', 'max_nt', 'exhausted', None]
    reason_labels = ['Bootstrap', 'Word-context', 'Max NT', 'Exhausted', 'Unknown']
    reason_colors = ['#2196F3', '#FF9800', '#F44336', '#9E9E9E', '#BDBDBD']
    bar_data = {nt: [] for nt in nt_vals}
    for n_nt in nt_vals:
        subset = [r for r in valid if r['n_nonterminals'] == n_nt]
        total = len(subset) if subset else 1
        for sr in stop_reasons:
            count = sum(1 for r in subset if r.get('stop_reason') == sr)
            bar_data[n_nt].append(count / total)

    x_pos = np.arange(len(nt_vals))
    bottom = np.zeros(len(nt_vals))
    for i, (sr, label, color) in enumerate(
            zip(stop_reasons, reason_labels, reason_colors)):
        vals = [bar_data[nt][i] for nt in nt_vals]
        ax.bar(x_pos, vals, 0.6, bottom=bottom, label=label, color=color,
               alpha=0.85)
        bottom += vals
    ax.set_xticks(x_pos)
    ax.set_xticklabels([f'{nt} NTs' for nt in nt_vals])
    ax.set_ylabel('Fraction of trials')
    ax.set_title('Which test triggered the stop?')
    ax.legend(fontsize=8, loc='upper right')
    ax.set_ylim(0, 1.05)
    ax.grid(True, alpha=0.2, axis='y')

    # --- Plot 5: Grammar difficulty vs detection error ---
    ax = axes[1, 1]
    for n_nt in nt_vals:
        subset = [r for r in valid if r['n_nonterminals'] == n_nt]
        eff_ctx = [r.get('eff_ctx_log_condition_number', 0) for r in subset]
        deltas = [abs(r['delta']) for r in subset]
        ax.scatter(eff_ctx, deltas, c=[nt_color[n_nt]], alpha=0.6, s=40,
                   label=f'{n_nt} NTs', edgecolors='white', linewidth=0.5)
    ax.set_xlabel('Effective context log condition number')
    ax.set_ylabel('|Delta| (absolute error)')
    ax.set_title('Grammar difficulty vs detection error')
    ax.legend(fontsize=8)
    ax.grid(True, alpha=0.2)

    # --- Plot 6: Corpus size effect + stopping reason accuracy ---
    ax = axes[1, 2]
    # Bar chart: accuracy broken down by stopping reason
    x_pos = np.arange(len(nt_vals))
    bar_w = 0.35
    for j, reason in enumerate(['bootstrap', 'word_ctx']):
        rates = []
        totals = []
        for n_nt in nt_vals:
            subset = [r for r in valid
                      if r['n_nonterminals'] == n_nt
                      and r.get('stop_reason') == reason]
            n = len(subset)
            c = sum(1 for r in subset if r['correct_count'])
            rates.append(c / n if n > 0 else 0)
            totals.append(f'{c}/{n}')
        offset = (j - 0.5) * bar_w
        clr = '#2196F3' if reason == 'bootstrap' else '#FF9800'
        label = 'Bootstrap' if reason == 'bootstrap' else 'Word-context'
        bars = ax.bar(x_pos + offset, rates, bar_w * 0.9,
                      label=label, color=clr, alpha=0.85)
        for k, (bar, ct) in enumerate(zip(bars, totals)):
            ax.text(bar.get_x() + bar.get_width() / 2,
                    bar.get_height() + 0.02,
                    ct, ha='center', va='bottom', fontsize=7)
    ax.set_xticks(x_pos)
    ax.set_xticklabels([f'{nt} NTs' for nt in nt_vals])
    ax.set_ylabel('Accuracy when this test triggers')
    ax.set_title('Accuracy by stopping test')
    ax.legend(fontsize=8)
    ax.set_ylim(0, 1.15)
    ax.grid(True, alpha=0.2, axis='y')

    plt.tight_layout(rect=[0, 0, 1, 0.96])
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"Plot saved to {output_path}")


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description='Evaluate NMF auto-detection on synthetic grammars')
    parser.add_argument('output', help='Output JSON file for results')
    parser.add_argument('--plot', help='Output plot file (e.g. results.png)')
    parser.add_argument('--repeats', type=int, default=3,
                        help='Number of random grammars per config (default 3)')
    parser.add_argument('--quick', action='store_true',
                        help='Run a smaller experiment grid for quick testing')
    parser.add_argument('--verbose', action='store_true',
                        help='Enable verbose logging')
    args = parser.parse_args()

    if args.verbose:
        logging.basicConfig(level=logging.INFO)

    results = run_all_experiments(args)

    # Save results (omit kernel lists and tracebacks for compactness)
    save_results = []
    for r in results:
        sr = dict(r)
        sr.pop('kernels', None)
        sr.pop('fixed_kernels', None)
        sr.pop('traceback', None)
        save_results.append(sr)

    with open(args.output, 'w') as f:
        json.dump(save_results, f, indent=2)
    print(f"\nResults saved to {args.output}")

    print_summary(results)

    if args.plot:
        plot_results(results, args.plot)
